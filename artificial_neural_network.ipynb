{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ocean - Deep Learning: Introdução com Keras e Python (Parte 2).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAe4gKrn2WMg"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist # MNIST database\n",
        "from tensorflow.python.keras import Sequential # Model of our neural network\n",
        "from tensorflow.python.keras.layers import Dense, Dropout # Neurons (network base) and Regularizer (avoids overfitting)\n",
        "from tensorflow.compat.v1.keras.optimizers import RMSprop # Optimizer (back propagation)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llsrM2hw33c0"
      },
      "source": [
        "# Loading training and test data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLtZGYiq4i_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96231060-b20d-4954-bde5-b2aa3c890b55"
      },
      "source": [
        "print(\"Number of images for training:\", len(x_train))\n",
        "print(\"Number of images for testing:\", len(x_test))\n",
        "print(\"x_train type:\", type(x_treino))\n",
        "\n",
        "first_image = x_train[0]\n",
        "first_image_representation = y_train[0]\n",
        "\n",
        "print(\"What image 0 represents:\", first_image_representation)\n",
        "print(\"First image format:\", first_image.shape, type(first_image.shape))\n",
        "\n",
        "# print(first_image)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of images for training: 60000\n",
            "Number of images for testing: 10000\n",
            "x_train type: <class 'numpy.ndarray'>\n",
            "What image 0 represents: 5\n",
            "First image format: (28, 28) <class 'tuple'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "h6DyhlaaI_Bt",
        "outputId": "14d4f9ad-0c50-4013-9b73-d884ebf04137"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "index = 5000\n",
        "\n",
        "print(\"This image represents:\", y_treino[index])\n",
        "plt.imshow(x_treino[index], cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This image represents: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAN8ElEQVR4nO3df6xU9ZnH8c+zUkXlBkFubtCy0m38Q7OytE7IIkpcK8RfEZooFpOGjc1SE4lFiVnjmtTEf4yxJSSu1dsVC2uloq0rf5jdCmJME9M4KKsoKCxeUskVLjFa648g8uwf99Bc8Z7vDHPOzJl7n/crmczMeebMeRzvh3Pu+Z65X3N3ARj//qbqBgB0BmEHgiDsQBCEHQiCsANBTOjkxqZNm+YzZ87s5CaBUAYGBnTo0CEbrVYo7GZ2haQ1kk6S9B/ufl/q9TNnzlS9Xi+ySQAJtVott9byYbyZnSTp3yVdKel8SUvN7PxW3w9AexX5nX2OpD3uvtfdD0v6jaRF5bQFoGxFwn62pD+NeP5etuwrzGy5mdXNrD40NFRgcwCKaPvZeHfvd/eau9d6e3vbvTkAOYqEfb+kGSOefzNbBqALFQn7K5LONbNvmdnJkn4gaVM5bQEoW8tDb+5+xMxWSPofDQ+9rXX3N0vrDECpCo2zu/tzkp4rqRcAbcTlskAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCk3ZbGYDkj6W9KWkI+5eK6MpAOUrFPbMP7n7oRLeB0AbcRgPBFE07C7p92a2zcyWj/YCM1tuZnUzqw8NDRXcHIBWFQ37xe7+XUlXSrrFzOYf/wJ373f3mrvXent7C24OQKsKhd3d92f3ByU9I2lOGU0BKF/LYTez082s59hjSQsl7SirMQDlKnI2vk/SM2Z27H2ecPf/LqUrAKVrOezuvlfSP5TYC4A2YugNCIKwA0EQdiAIwg4EQdiBIMr4Igwq9thjj+XWsqHRXGeeeWayvnPnzmR97ty5yfoll1ySrKNz2LMDQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBDjZpz9iSeeSNZfe+21ZH3t2rVlttNRH374YcvrTpiQ/hE4fPhwsj5x4sRk/bTTTsutzZo1K7nuxo0bk3X+8tGJYc8OBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0GMqXH222+/Pbe2Zs2a5LpHjx4tu51xodE4eiOff/55y/UXX3wxue4NN9yQrG/YsCFZ7+vrS9ajYc8OBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0GMqXH2p556KrfWaBy90XenTz311JZ6KsO8efOS9cWLF3eokxO3efPmZH39+vW5tYGBgeS6W7duTdaXLl2arD/55JO5tYjfhW+4ZzeztWZ20Mx2jFg21cyeN7Pd2f2U9rYJoKhmDuN/JemK45bdKWmLu58raUv2HEAXaxh2d39J0gfHLV4kaV32eJ2k7j3OBCCp9RN0fe4+mD1+X1LuRchmttzM6mZWHxoaanFzAIoqfDbe3V2SJ+r97l5z91rEkyJAt2g17AfMbLokZfcHy2sJQDu0GvZNkpZlj5dJeracdgC0iw0fhSdeYLZB0qWSpkk6IOmnkv5L0kZJfytpn6Ql7n78SbyvqdVqXq/XW272nXfeya3t2LEjtyZJCxYsSNZ7enpa6glpe/fuza1dffXVyXV37dpVaNsPPPBAbm3VqlWF3rtb1Wo11et1G63W8KIad8+7cuF7hboC0FFcLgsEQdiBIAg7EARhB4Ig7EAQDYfeylR06A3jy9NPP52sX3/99YXef9q0abm18XrpdmrojT07EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBDGmpmzG2PPQQw/l1tr9tw0+++yz3Nq2bduS61544YVlt1M59uxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EATj7OPA4OBgbu3xxx9Prrt69eqy2/mKVG/t9sknn+TWLrvssuS6H330UdntVK7hnt3M1prZQTPbMWLZPWa238y2Z7er2tsmgKKaOYz/laQrRlm+2t1nZ7fnym0LQNkaht3dX5L0QQd6AdBGRU7QrTCz17PD/Cl5LzKz5WZWN7P6eJ1fCxgLWg37LyR9W9JsSYOSfpb3Qnfvd/eau9d6e3tb3ByAoloKu7sfcPcv3f2opF9KmlNuWwDK1lLYzWz6iKffl7Qj77UAukPDcXYz2yDpUknTzOw9ST+VdKmZzZbkkgYk/biNPY57mzdvTtYbfff6kUceya29++67LfU03t10001Vt9BxDcPu7ktHWfxoG3oB0EZcLgsEQdiBIAg7EARhB4Ig7EAQfMW1BLt3707Wb7755mT9hRdeKLOdE3LOOeck61Om5F4J3ZR77703tzZx4sTkuitWrEjW33777ZZ6kqSzzjqr5XXHKvbsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAE4+xNSv3J5QcffDC57t69e5P1SZMmJeuTJ09O1m+77bbcWqPx5IsuuihZbzQO306N/rsb6enpya1dc801hd57LGLPDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBMM7epJdffjm31mgc/dprr03WV61alazPnz8/WR+rtm/fnqzv27ev0PufcsopubXzzjuv0HuPRezZgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIxtmb9PDDD+fWZs2alVz37rvvLrudcWHPnj3J+oEDBwq9/+WXX15o/fGm4Z7dzGaY2VYze8vM3jSzn2TLp5rZ82a2O7svNpsAgLZq5jD+iKRV7n6+pH+UdIuZnS/pTklb3P1cSVuy5wC6VMOwu/ugu7+aPf5Y0k5JZ0taJGld9rJ1kha3q0kAxZ3QCTozmynpO5L+KKnP3Qez0vuS+nLWWW5mdTOrDw0NFWgVQBFNh93MJkn6raSV7v7nkTV3d0k+2nru3u/uNXev9fb2FmoWQOuaCruZfUPDQf+1u/8uW3zAzKZn9emSDranRQBlaDj0ZmYm6VFJO9395yNKmyQtk3Rfdv9sWzrsElOnTs2tMbTWmtTXhptxxhlnJOu33nprofcfb5oZZ58n6YeS3jCzY19AvkvDId9oZj+StE/Skva0CKAMDcPu7n+QZDnl75XbDoB24XJZIAjCDgRB2IEgCDsQBGEHguArrmirCy64ILe2a9euQu+9cOHCZH3u3LmF3n+8Yc8OBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0Ewzo62GhgYyK0dOXIkue7kyZOT9ZUrV7bSUljs2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMbZUciGDRuS9U8//TS31tPTk1y3v78/Wef76ieGPTsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBNHM/OwzJK2X1CfJJfW7+xozu0fSv0gayl56l7s/165GUY0vvvgiWb///vuT9ZNPPjm3dt111yXXXbKEWcDL1MxFNUckrXL3V82sR9I2M3s+q6129wfa1x6AsjQzP/ugpMHs8cdmtlPS2e1uDEC5Tuh3djObKek7kv6YLVphZq+b2Vozm5KzznIzq5tZfWhoaLSXAOiApsNuZpMk/VbSSnf/s6RfSPq2pNka3vP/bLT13L3f3WvuXuvt7S2hZQCtaCrsZvYNDQf91+7+O0ly9wPu/qW7H5X0S0lz2tcmgKIaht3MTNKjkna6+89HLJ8+4mXfl7Sj/PYAlKWZs/HzJP1Q0htmtj1bdpekpWY2W8PDcQOSftyWDlGp4X/r8914443J+uzZs3NrCxYsaKkntKaZs/F/kDTa/3HG1IExhCvogCAIOxAEYQeCIOxAEIQdCIKwA0Hwp6SRNGFC+kfkjjvu6FAnKIo9OxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EYe7euY2ZDUnaN2LRNEmHOtbAienW3rq1L4neWlVmb+e4+6h//62jYf/axs3q7l6rrIGEbu2tW/uS6K1VneqNw3ggCMIOBFF12Psr3n5Kt/bWrX1J9NaqjvRW6e/sADqn6j07gA4h7EAQlYTdzK4ws7fNbI+Z3VlFD3nMbMDM3jCz7WZWr7iXtWZ20Mx2jFg21cyeN7Pd2f2oc+xV1Ns9ZrY/++y2m9lVFfU2w8y2mtlbZvammf0kW17pZ5foqyOfW8d/ZzezkyS9I2mBpPckvSJpqbu/1dFGcpjZgKSau1d+AYaZzZf0F0nr3f3vs2X3S/rA3e/L/qGc4u7/2iW93SPpL1VP453NVjR95DTjkhZL+mdV+Nkl+lqiDnxuVezZ50ja4+573f2wpN9IWlRBH13P3V+S9MFxixdJWpc9XqfhH5aOy+mtK7j7oLu/mj3+WNKxacYr/ewSfXVEFWE/W9KfRjx/T90137tL+r2ZbTOz5VU3M4o+dx/MHr8vqa/KZkbRcBrvTjpumvGu+examf68KE7Qfd3F7v5dSVdKuiU7XO1KPvw7WDeNnTY1jXenjDLN+F9V+dm1Ov15UVWEfb+kGSOefzNb1hXcfX92f1DSM+q+qagPHJtBN7s/WHE/f9VN03iPNs24uuCzq3L68yrC/oqkc83sW2Z2sqQfSNpUQR9fY2anZydOZGanS1qo7puKepOkZdnjZZKerbCXr+iWabzzphlXxZ9d5dOfu3vHb5Ku0vAZ+f+T9G9V9JDT199J+t/s9mbVvUnaoOHDui80fG7jR5LOlLRF0m5JmyVN7aLe/lPSG5Je13CwplfU28UaPkR/XdL27HZV1Z9doq+OfG5cLgsEwQk6IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQji/wEAVC2MzW8YOAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUWIN9quJdDl"
      },
      "source": [
        "# Transforming the image matrix into a vector\n",
        "\n",
        "number_train = len(x_train) # 60000\n",
        "number_test = len(x_test) # 10000\n",
        "\n",
        "image_resolution = x_train[0].shape # (28, 28)\n",
        "all_resolution = image_resolution[0] * image_resolution[1] # 28 * 28 = 784\n",
        "\n",
        "x_train = x_train.reshape(number_train, all_resolution)\n",
        "x_test = x_test.reshape(number_test, all_resolution)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0RNJ__cJo7u",
        "outputId": "5763ffd3-9b80-4d8a-fc35-5aa42717c217"
      },
      "source": [
        "print(\"Quantity of items in x_train [0]:\", len(x_train[0]))\n",
        "\n",
        "# How was x_train [0]?\n",
        "print('\\n\\n',x_train[0])"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quantity of items in x_train [0]: 784\n",
            "\n",
            "\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
            " 247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
            " 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
            "   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
            "  82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
            " 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
            " 225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            " 253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
            " 253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
            "  80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PNt2ayJJrXU",
        "outputId": "7e247218-a812-4bc6-aa41-f41cf4e1757a"
      },
      "source": [
        "# Data normalization\n",
        "\n",
        "# 255 turns 1\n",
        "# 127 turns 0.5\n",
        "# 0   turns 0\n",
        "\n",
        "# We need to ensure that the maximum input value is 1\n",
        "# Since the image currently provides a maximum value of 255, we need to normalize them\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "print(x_train[0][350], type(x_train[0][350]))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.27450982 <class 'numpy.float32'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFV4_E7zJ1HI",
        "outputId": "72a90072-9d2f-4af0-9a4f-3f2f39d63317"
      },
      "source": [
        "# Viewing normalized data\n",
        "\n",
        "print(\"Standardized data:\", x_train[0])"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Standardized data: [0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
            " 0.49411765 0.53333336 0.6862745  0.10196079 0.6509804  1.\n",
            " 0.96862745 0.49803922 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.11764706 0.14117648 0.36862746 0.6039216\n",
            " 0.6666667  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            " 0.88235295 0.6745098  0.99215686 0.9490196  0.7647059  0.2509804\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.19215687\n",
            " 0.93333334 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.9843137  0.3647059  0.32156864\n",
            " 0.32156864 0.21960784 0.15294118 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.07058824 0.85882354 0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.99215686 0.7764706  0.7137255\n",
            " 0.96862745 0.94509804 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.3137255  0.6117647  0.41960785 0.99215686\n",
            " 0.99215686 0.8039216  0.04313726 0.         0.16862746 0.6039216\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.05490196 0.00392157 0.6039216  0.99215686 0.3529412\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.54509807 0.99215686 0.74509805 0.00784314 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.04313726\n",
            " 0.74509805 0.99215686 0.27450982 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.13725491 0.94509804\n",
            " 0.88235295 0.627451   0.42352942 0.00392157 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.31764707 0.9411765  0.99215686\n",
            " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
            " 0.5882353  0.10588235 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.0627451  0.3647059  0.9882353  0.99215686 0.73333335\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.9764706  0.99215686 0.9764706  0.2509804  0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.18039216 0.50980395 0.7176471  0.99215686\n",
            " 0.99215686 0.8117647  0.00784314 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.15294118 0.5803922\n",
            " 0.8980392  0.99215686 0.99215686 0.99215686 0.98039216 0.7137255\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.09411765 0.44705883 0.8666667  0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.7882353  0.30588236 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.09019608 0.25882354 0.8352941  0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.7764706  0.31764707 0.00784314\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.07058824 0.67058825\n",
            " 0.85882354 0.99215686 0.99215686 0.99215686 0.99215686 0.7647059\n",
            " 0.3137255  0.03529412 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.21568628 0.6745098  0.8862745  0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.95686275 0.52156866 0.04313726 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.53333336 0.99215686\n",
            " 0.99215686 0.99215686 0.83137256 0.5294118  0.5176471  0.0627451\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm4eWoUbJ5p-",
        "outputId": "a3a75151-4041-40ee-ceef-bf2c5183e2a8"
      },
      "source": [
        "# Preparation of the output layer (output)\n",
        "\n",
        "# Transform unique values into categorical variables\n",
        "# Number 0 -> [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "# Number 1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "# ...\n",
        "# Number 9 -> [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
        "\n",
        "unique_values = set(y_train) # {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
        "print(unique_values)\n",
        "\n",
        "number_unique_values = len(unique_values) # 10\n",
        "print(number_unique_values)\n",
        "\n",
        "print(\"y_train[0] before:\", y_train[0])\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, number_unique_values)\n",
        "y_test = keras.utils.to_categorical(y_test, number_unique_values)\n",
        "\n",
        "print(\"y_train[0] ofter:\", y_train[0])"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
            "10\n",
            "y_train[0] before: 5\n",
            "y_train[0] ofter: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTv3a1iDKApK",
        "outputId": "910787ed-3e66-465b-dd78-f1722505deb1"
      },
      "source": [
        "# Creating the neural network model\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "# 30 neurons\n",
        "# Activation function: ReLU\n",
        "# As we are in the first hidden layer, we need to inform the format of the input layer\n",
        "model.add(Dense(30, activation='relu', input_shape=(all_resolution,)))\n",
        "\n",
        "# We added a regularizer, helps to avoid overfitting\n",
        "# In this case, it will be Dropout\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Second hidden layer\n",
        "# 20 neurons\n",
        "# Activation function: ReLU\n",
        "model.add(Dense(20, activation='relu'))\n",
        "\n",
        "# Another regularizer after the second hidden layer\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# We finish with the output layer, informing the number of unique values, which in this case is 10\n",
        "model.add(Dense(number_unique_values, activation='softmax'))\n",
        "\n",
        "# Displays the summary of the created model\n",
        "model.summary()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 30)                23550     \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 20)                620       \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                210       \n",
            "=================================================================\n",
            "Total params: 24,380\n",
            "Trainable params: 24,380\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo1opdB_KS7Y"
      },
      "source": [
        "# Compiles the model\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqvX9NJiK8OY",
        "outputId": "4ba841e9-5cd0-4c45-ed3c-5fe4f3f32dcc"
      },
      "source": [
        "# Trains the model\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.7965 - accuracy: 0.7522 - val_loss: 0.2878 - val_accuracy: 0.9187\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4445 - accuracy: 0.8692 - val_loss: 0.2320 - val_accuracy: 0.9321\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3780 - accuracy: 0.8891 - val_loss: 0.2068 - val_accuracy: 0.9384\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3395 - accuracy: 0.9007 - val_loss: 0.1905 - val_accuracy: 0.9449\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3212 - accuracy: 0.9068 - val_loss: 0.1794 - val_accuracy: 0.9458\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3023 - accuracy: 0.9121 - val_loss: 0.1727 - val_accuracy: 0.9499\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2907 - accuracy: 0.9151 - val_loss: 0.1755 - val_accuracy: 0.9498\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2837 - accuracy: 0.9182 - val_loss: 0.1687 - val_accuracy: 0.9511\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2727 - accuracy: 0.9217 - val_loss: 0.1578 - val_accuracy: 0.9560\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.2670 - accuracy: 0.9230 - val_loss: 0.1566 - val_accuracy: 0.9570\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "O6gxlIAlK_dr",
        "outputId": "8b31c3db-7398-4b9c-c154-c7c73ea36436"
      },
      "source": [
        "# Making our predictions\n",
        "\n",
        "index = 7\n",
        "\n",
        "print(\"Categorical value in y_test[index]:\", y_test[index])\n",
        "\n",
        "# Prepare the image for prediction\n",
        "image = x_test[index].reshape((1, all_resolution))\n",
        "\n",
        "prediction = model.predict(image)\n",
        "print(\"\\nPrevision:\", prediction)\n",
        "\n",
        "# Transform prediction into something we can understand\n",
        "\n",
        "import numpy as np\n",
        "prediction_class = np.argmax(prediction, axis=-1)\n",
        "print(\"\\nAdjusted prediction:\", prediction_class)\n",
        "\n",
        "# Just to view the image\n",
        "(x_train_img, y_train_img), (x_test_img, y_test_img) = mnist.load_data()\n",
        "plt.imshow(x_test_img[index], cmap=plt.cm.binary)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Categorical value in y_test[index]: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "\n",
            "Prevision: [[3.3543307e-05 1.3859337e-04 9.4162624e-06 1.2904870e-03 1.0409855e-02\n",
            "  5.3913088e-04 1.8316828e-06 6.9415383e-03 2.5326253e-03 9.7810292e-01]]\n",
            "\n",
            "Adjusted prediction: [9]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2c9a3b3780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yokfsDtOLQe2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}